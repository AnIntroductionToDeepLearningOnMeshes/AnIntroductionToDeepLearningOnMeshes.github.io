<!-- 
note: to test on local
1. type `python3 -m http.server` or `npx http-server ./ -c-1`
2. open browser and go to `http://localhost:8000` 
-->

<!DOCTYPE html>
<html>

<head>
  <title> 
    An Introduction to Deep Learning on Meshes
  </title>
  <link rel="stylesheet" type="text/css" href="style.css">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- syntax highlight -->
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.4.1/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.4.1/highlight.min.js"></script>
  <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.4.1/highlight.min.js"></script> -->
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- include three.js from CDN -->
  <script src="https://threejs.org/build/three.js"></script>
  <script src='https://threejs.org/examples/js/controls/OrbitControls.js'></script>
  <script src='https://threejs.org/examples/js/loaders/OBJLoader.js'></script>
  <script src="meshes/mesh.js"></script>

  <!-- include text icon at fontawesome.com -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css">
</head>
<body>
  <!-- <nav id="navBar">
    <div class="container">
      <ul>
        <li> <a hred="#"> Home </a> </li>
        <li> <a hred="#"> Course Note </a> </li>
        <li> <a hred="#"> Code </a> </li>
        <li> <a hred="#"> Contact </a> </li>
      </ul>
    </div>
  </nav> -->

  <section id="teaser">
    <div>
      <h1> 
        An Introduction to Deep Learning on Meshes
      </h1>  
    </div>
  </section> 

  <div class="wrapper">

  <!-- The sidebar -->
  <div class="sidebar">
    <a href="#home">Home</a>
    <a href="#materials">Course Materials</a>
    <a href="#datasets">Dateset</a>
    <a href="#demos">Demos</a>
    <a href="#contacts">Contacts</a>
  </div>

  <div class="container" id="home">
    <section id="mainBody">
      <h1> Course Objective </h1>
      <p>
        This course introduces the fundamentals of machine learning techniques on meshes. We start with a short introduction of machine learning on regular structures (e.g., images), and discuss their generalization to the irregular mesh structure. Despite several alternative representations exist (e.g., implicits, voxels, point clouds), we focus our discussion on the techniques directly defined on surface triangle meshes, which is one of the most commonly used representations in graphics over the decades. Specifically, we will cover the building blocks of a mesh convolutional neural network, including convolution, pooling, regularization, and loss functions. We will also cover how to apply convolutional networks to classic geometry processing tasks, such as geometric texture synthesis, shape classification, and subdivision. We propose a mesh MNIST dataset for research prototyping and hand-on demos to these learning tasks.<br>
      </p>

      <h1 id="materials"> Course Materials </h1>
      <p>
        <!-- <a href="pdfs/test.pdf"> <i class="fa fa-file-pdf fa-4x fa-fw"></i> </a>
        <a href="https://youtu.be/-CnkgGosSLw"> <i class="fab fa-youtube fa-4x fa-fw"></i> </a>
        <a href="https://github.com/libigl/libigl/"> <i class="fab fa-github fa-4x fa-fw"></i> </a> -->
        <a href="pdfs/test.pdf"> <i class="fa fa-file-pdf fa-4x fa-fw"></i> </a>
      </p>

      <!-- for it to work locally, we have to do
      /Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --allow-file-access-from-files -->
      <h1 id="datasets"> Datasets </h1>
      The <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> dataset contains thousands of handwritten digits. This is commonly used as the <em>Hello World</em> for deep learning on images. We create an analogous 3D mesh MNIST dataset for 3D deep learning in <a href="https://drive.google.com/drive/folders/1CYVoGOiY2rVSzlF5sDpuAgmbwKBYuEgu?usp=sharing">Link</a>.
      <div id="mesh1" class="center">
        <script>render('#mesh1', 'meshes/data.obj', THREE.FlatShading);</script>
      </div>


      <h1 id="demos"> Demos </h1>
      We introduce a series of self-contained examples based on open source libraries such as <a href="https://github.com/google/jax">JAX</a> and <a href="https://pytorch.org">PyTorch</a>. The purpose of these examples is to demonstrate how to implement a simple machine learning model on meshes. <br>

      <h3> 1. Simple mesh CNN without pooling </h3>

      We present a basic example on using mesh CNN to classify meshes of "1" and meshes of "2" from our <a href="https://drive.google.com/drive/folders/1CYVoGOiY2rVSzlF5sDpuAgmbwKBYuEgu?usp=sharing">meshMNIST</a> dataset. We will cover the full pipeline of loading a shape, computing input features, define a mesh CNN, and the network training. We recommend readers to use well-optimized functions for e.g. <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">loading training data</a> or <a href="https://jax.readthedocs.io/en/latest/jax.experimental.stax.html">network components</a>. But for clarity purposes, we implement an as-simple-as-possible mesh CNN from scratch using JAX without those utility functions. <br><br>
      
      Let's get started by import the basic libraries that we will need in this tutorial <br> 
      <script src="https://gist.github.com/HTDerekLiu/27bed2edec04f617d817bbaf55684d12.js"></script>
      
      We represent each shape as a surface triangle mesh and store as a <em>triangle soup</em>. Specifically, the mesh is represented by two matrices: 
      <ul>
        <li>a #vertices by 3 matrix of vertex positions <code>V</code>.</li>
        <li>a #faces by 3 matrix of triangle indices <code>F</code> into the vertex list <code>V</code>.</li>
      </ul>
      We then pre-compute the information that are needed for the training process. This includes 
      <ul>
        <li>a #edges by 2 matrix of (undirected) edge indices <code>E</code>.</li>
        <li>a #edges by 4 matrix of flap edge indices <code>flap</code> (4 boundary edges of each two adjacent triangles) into the edge list <code>E</code>.</li>
        <li>a #edges by n matrix of input features <code>fE</code> where n is the featrue dimension.</li>
      </ul>

      <script src="https://gist.github.com/HTDerekLiu/39987bfa39eb99e476386aee8ea061c2.js"></script>

      This <code>compute_input</code> computes the input feature for each edge. Which input feature to compute is a choice to make, here we simply compute the dihedral angle and the 4 edge length ratios for simplicity

      <script src="https://gist.github.com/HTDerekLiu/d48402a1d85eff0e7f4fb6317f5ff89f.js"></script>

      Since this pre-processing usually takes a while, we often process the entire dataset once and save the information 
      <script src="https://gist.github.com/HTDerekLiu/9bccae39805639b009d463fe6752da5c.js"></script>

      After processing the meshes, we can now define the mesh CNN. Similar to a lot of mesh CNNs (e.g., <a href="https://ranahanocka.github.io/MeshCNN/">MeshCNN</a>), our architecture consists of a bunch of convolution layers, followed by a global pooling and a fully connected layers. For simplicity, we omit the mesh pooling processing in this toy example. <br> <br> 

      In each mesh convolution, the input is a n dimensional function defined on each edge <code>fE</code> in our case. For other applications, this could be a function defined on each face/vertex. No matter "where" we store the input function, the first step in mesh convolution is to re-index this function into a format for fast convolutions. In this example, we will re-index the #edges by n edge functions <code>fE</code> into flap functions <code>fP</code> following the formula in <a href="https://ranahanocka.github.io/MeshCNN/">MeshCNN</a> Equation 2 as
      <script src="https://gist.github.com/HTDerekLiu/a8c9c659675d7032049e63aced798442.js"></script>
      Each flap function is a n by 5 matrix, thus <code>fP</code> is a #edges by n by 5 3D matrix.

      After that, mesh convolution can be performed easily with 2D convolution, where each convolution filter has size n by 5 and it outputs a scalar value. We implement it from scratch for clarity, but one should switch to a more well-optimized implementation for performance reasons
      <script src="https://gist.github.com/HTDerekLiu/b40e50b8f8de3ee731d18f2dded56e06.js"></script>

      With the structure of mesh convolution in mind, we can now initialize the network parameters and define the forward pass (convolutions, global pooling, fully connected multilayer perceptron) as
      <script src="https://gist.github.com/HTDerekLiu/97ba563fd50bcc7da9716a998d04a7d9.js"></script>

      The rest of the pipeline is the same as e.g. image based classification networks. We need to define the loss function, optimizer, parameter update functions 
      <script src="https://gist.github.com/HTDerekLiu/cbf08cbdf6bd50569489776e4f5be332.js"></script>

      Then start the network training 
      <script src="https://gist.github.com/HTDerekLiu/3c694a7bd98b4228c725063e6901e376.js"></script>
      This training code takes one shape at a time and use stochastic gradient descent to optimize the network. One could also accumulate the gradient from a batch of shapes before taking a gradient step. Ideally, one should also use the <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">dataloader</a> so that loading the data won't be the bottleneck of training. One could also use a validation set to early stop the training to avoid overfitting.






      
      
      
      
      <!-- First, let's start by loading the library and the our mesh MNIST dataset<br><br>
      <script src="https://gist.github.com/HTDerekLiu/60a323f8e233c2af84dccceff7ee0810.js"></script>

      Next, let's define a simple mesh convolutional network without mesh pooling. The network takes a triangle mesh as input, perform a series of mesh convolutions, follow by a global feature pooling, and make classifications based on the feature<br><br>
      <script src="https://gist.github.com/HTDerekLiu/21c51593f0519304eb6ef26662fac69d.js"></script>

      To train the network, we use a Cross-Entropy loss and a stochastic gradient descent optimizer<br><br>
      <script src="https://gist.github.com/HTDerekLiu/a8465906bb4f48107ccbc64c86456900.js"></script>

      Then we can simply train the network to minimize the loss function as<br><br>
      <script src="https://gist.github.com/HTDerekLiu/d3c3b5c5ad540996ae067bbf9d3be41b.js"></script>

      After the training is complete, we can easily use our network to classify unseen data as<br><br>
      <script src="https://gist.github.com/HTDerekLiu/7f091f55ba9d77ccf2ae6251d0568697.js"></script> -->

      <!-- <script src="https://gist.github.com/HTDerekLiu/d5cb5ec24f46a1355049d11ad5cdd6fc.js"></script>
      <figure>
        <img src="images/example_image.jpg" alt="example image">
        <figcaption> Fig.1 example image caption example image caption example image caption example image caption example image caption example image caption </figcaption>  
      </figure>

      <figure>
        <img src="images/example_gif.gif" alt="example gif">
        <figcaption> Fig.2 example image caption example image caption example image caption example im<meta name="viewport" content="width=device-width, initial-scale=1.0">age caption example image caption example image caption </figcaption>  
      </figure> -->

      <h1 id="contacts"> Contacts </h1>
      This course of deep learning on meshes is developed by <a href="https://www.cs.tau.ac.il/~hanocka/">Rana Hanocka</a> and <a href="https://www.dgp.toronto.edu/~hsuehtil/">Hsueh-Ti Derek Liu</a>. If any questions or suggestions, please <a href="mailto:hsuehtil@cs.toronto.edu,rana@hanocka.com">contact us</a>.

      </div>  <!-- end of wrapper (main body above) -->
    </section> 
  </div>
  </div>
  
  <footer id="mainFooter">
    <p>
      Copyright &copy;2021 An Introduction to Deep Learning on Meshes
    </p>
  </footer>
</body>
</html>

    <!-- visualize 3d model -->
		<!-- <script>
      const scene = new THREE.Scene();
      const camera = new THREE.PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 0.1, 1000 );

      const renderer = new THREE.WebGLRenderer();
      renderer.setSize( window.innerWidth, window.innerHeight );
      document.body.appendChild( renderer.domElement );

      const loader = new THREE.OBJLoader();
      loader.load(
        // resource URL
        "/meshes/spot.obj",

        // Here the loaded data is assumed to be an object
        function ( obj ) {
          scene.add( obj );
        },

        // onProgress callback
        function ( xhr ) {
          console.log( (xhr.loaded / xhr.total * 100) + '% loaded' );
        },

        // onError callback
        function ( err ) {
          console.error( 'An error happened' );
        }
      );

      // const geometry = new THREE.BoxGeometry();
      // const material = new THREE.MeshBasicMaterial( { color: 0x00ff00 } );
      // const cube = new THREE.Mesh( geometry, material );
      // scene.add( cube );

      camera.position.z = 5;

      const animate = function () {
				requestAnimationFrame( animate );

				// cube.rotation.x += 0.01;
				// cube.rotation.y += 0.01;

				renderer.render( scene, camera );
			};

			animate();
    </script> -->


      <!-- example style text -->
      <!-- <p>
        <em> this is an example of "em" </em> <br>

        <strong> this is an example of "strong" </strong><br>

        <code>
          code block
        </code>
        <pre><code class="python">
import numpy as np
x = np.array([1,2,3])
        </code></pre>
        
      </p> -->
      <!-- end example style text -->

      <!-- example list -->
      <!-- <ul>
        <li> this is an example list item 1 </li>
        <li> this is an example list item 2 </li>
        <li> this is an example list item 3 </li>
        <li> this is an example list item 4 </li>
      </ul>  -->
      <!-- end of example list  -->

      <!-- example embed gist -->
      <!-- <script src="https://gist.github.com/HTDerekLiu/d5cb5ec24f46a1355049d11ad5cdd6fc.js"></script> -->
      <!-- end of embed list  -->
      
      <!-- example table -->
      <!-- <table class="center">
        <thead>
          <th> table head 1</th>
          <th> table head 2</th>
          <th> table head 3</th>
        </thead>
        <tbody>
          <tr> 
            <td> content 1 </td>
            <td> content 2 </td>
            <td> content 3 </td>
          </tr>
          <tr> 
            <td> content 1 </td>
            <td> content 2 </td>
            <td> content 3 </td>
          </tr>
          <tr> 
            <td> content 1 </td>
            <td> content 2 </td>
            <td> content 3 </td>
          </tr>
        </tbody>
      </table> -->
      <!-- end of example table -->

      <!-- example image -->
      <!-- <figure>
        <img src="images/example_image.jpg" alt="example image">
        <figcaption> Fig.1 example image caption example image caption example image caption example image caption example image caption example image caption </figcaption>  
      </figure>

      <figure>
        <img src="images/example_gif.gif" alt="example gif">
        <figcaption> Fig.2 example image caption example image caption example image caption example im<meta name="viewport" content="width=device-width, initial-scale=1.0">age caption example image caption example image caption </figcaption>  
      </figure> -->

      <!-- <h1> Try to visualize meshes </h1>
      <p>
        random text random text random text random text random text random text random text random text random text random text random text random text  .. .  random text random text random text random text random text random text random text random text random text random text random text random text
      </p>
      <div class="three_container">
      <div id="mesh1" class="center">
        <script>render('#mesh1', 'meshes/bunny.obj', THREE.FlatShading);</script>
      </div>
      <div id="mesh2" class="center">
        <script>render('#mesh2', 'meshes/spot.obj', THREE.FlatShading);</script>
      </div> -->